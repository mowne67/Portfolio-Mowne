{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Television Image Detector.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyOk44LS4l/iHclYyLk4q1h3",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mowne67/Portfolio-Mowne/blob/main/Television_Image_Detector.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gQ0NR8Ha_JRW"
      },
      "source": [
        "#Television Image Detector using Tensorflow Keras\n",
        "An image processing neural network is designed that takes any image from the internet and detects the presence of a television in the image. The ***model is trained using a dataset that is created from scratch*** from a webscraper notebook which outputs a csv file of image URLs from DuckDuckGo search engine images.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9-dGr7r9GIaL"
      },
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import datasets, layers, models"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "w1-S9vg8Bd11"
      },
      "source": [
        "Two datasets were created using the Imagescraper. The `random.csv` file contains URLs of random images (not television) that are labelled as `0`. The `tvimage.csv` file contains URLs of images of television that are labelled as `1`.\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bGlURg4bKPFo"
      },
      "source": [
        "random=pd.read_csv(\"random.csv\")\n",
        "tvimage=pd.read_csv(\"tvimage.csv\")"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oQCJFl94Cn1X"
      },
      "source": [
        "The two datasets are combined to create a new DataFrame `tvtrain` which is going to be used for training."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Bu-wWp3syD8-"
      },
      "source": [
        "tvtrain=pd.DataFrame()\n",
        "tvtrain[\"URL\"]=list(random[\"URL\"])+list(tvimage[\"URL\"])\n",
        "tvtrain[\"Label\"]=list(random[\"Label\"])+list(tvimage[\"Label\"])"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VAjb0TTxyhXe",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 415
        },
        "outputId": "4e415890-56e0-480f-cc7e-81f25b812794"
      },
      "source": [
        "tvtrain"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>URL</th>\n",
              "      <th>Label</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>https://tse3.mm.bing.net/th?id=OIP.E0IO_W_4xEl...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>https://tse4.mm.bing.net/th?id=OIP.L-Uzd8nIU6G...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>https://tse3.mm.bing.net/th?id=OIP.0N_-pJLPt0l...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>https://tse3.explicit.bing.net/th?id=OIP.Gqhlz...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>https://tse1.mm.bing.net/th?id=OIP.HSPjjE1j3wD...</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>845</th>\n",
              "      <td>https://tse2.mm.bing.net/th?id=OIP.MuQkn-8N5vJ...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>846</th>\n",
              "      <td>https://tse1.mm.bing.net/th?id=OIP.c_JH2O92x9G...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>847</th>\n",
              "      <td>https://tse4.mm.bing.net/th?id=OIP.9ay-VVnljLF...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>848</th>\n",
              "      <td>https://tse4.mm.bing.net/th?id=OIP._Jc2jHL6eBB...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>849</th>\n",
              "      <td>https://tse4.mm.bing.net/th?id=OIP.s_iLHvPeCV3...</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>850 rows Ã— 2 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                   URL  Label\n",
              "0    https://tse3.mm.bing.net/th?id=OIP.E0IO_W_4xEl...      0\n",
              "1    https://tse4.mm.bing.net/th?id=OIP.L-Uzd8nIU6G...      0\n",
              "2    https://tse3.mm.bing.net/th?id=OIP.0N_-pJLPt0l...      0\n",
              "3    https://tse3.explicit.bing.net/th?id=OIP.Gqhlz...      0\n",
              "4    https://tse1.mm.bing.net/th?id=OIP.HSPjjE1j3wD...      0\n",
              "..                                                 ...    ...\n",
              "845  https://tse2.mm.bing.net/th?id=OIP.MuQkn-8N5vJ...      1\n",
              "846  https://tse1.mm.bing.net/th?id=OIP.c_JH2O92x9G...      1\n",
              "847  https://tse4.mm.bing.net/th?id=OIP.9ay-VVnljLF...      1\n",
              "848  https://tse4.mm.bing.net/th?id=OIP._Jc2jHL6eBB...      1\n",
              "849  https://tse4.mm.bing.net/th?id=OIP.s_iLHvPeCV3...      1\n",
              "\n",
              "[850 rows x 2 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BE5Us6NIC9Jo"
      },
      "source": [
        "Testing out the DataFrame:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "V2gaScm5wzJ6",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "598b72d5-8ad9-4dd9-ae09-48471290f143"
      },
      "source": [
        "tvimage[\"Label\"][440]"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O7iVqdELidpw",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "9c3f72ed-ba61-434e-a143-18a737e7f156"
      },
      "source": [
        "tvimage['URL'][45]"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'https://tse3.mm.bing.net/th?id=OIP.4xGA1b_IhOYC_GUzB87vkwHaHa&pid=Api'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "z9X9Jf-nDGWc"
      },
      "source": [
        "##Image Pre-Processing"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3Hqo-uaZDBhY"
      },
      "source": [
        "As these URLs contain the URLs of the jpeg files, `requests` library is used to open the jpeg image from the URL. Then, the jpeg file is converted into a numpy array with the size of `(800,400,3)` where the 3 is for the RGB dimension. To complete these tasks for all the URLs in the tvtrain dataframe, the function `preprocess` is created.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "627Lo7YhjfyO"
      },
      "source": [
        "from PIL import Image\n",
        "import requests\n",
        "from keras.preprocessing import image"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Yb2UO0UT0pr9"
      },
      "source": [
        "def preprocess(url):\n",
        "  img= Image.open(requests.get(url, stream=True).raw)\n",
        "  \n",
        "  img_array = image.img_to_array(img)\n",
        "\n",
        "  imag = tf.image.resize(img_array, (800,400))\n",
        "  return imag\n"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RuN1UicoFS6t"
      },
      "source": [
        "A new list called tvtrain_images is created where all the preprocessed images are stored as arrays. The list is converted to a numpy array."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tmlTvA-g4bLh",
        "outputId": "a3918707-fa8c-4623-ca69-8acd69d01ba9"
      },
      "source": [
        "tvtrain_images=[]\n",
        "for url in tvtrain[\"URL\"]:\n",
        "  tvtrain_images.append(preprocess(url))\n",
        "len(tvtrain_images)"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "850"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9GEzVvJx56_A",
        "outputId": "3cbfcbf4-325f-4fd6-ff49-c35ef3688e15"
      },
      "source": [
        "tvtrain_images=np.array(tvtrain_images)\n",
        "tvtrain_images.shape"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(850, 800, 400, 3)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "mIrXmu3SFxLb"
      },
      "source": [
        "The labels are stored in a numpy array."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "teVNAlP-4so9"
      },
      "source": [
        "tvtrain_labels=np.array(tvtrain[\"Label\"])\n",
        "tvtrain_labels=tvtrain_labels.reshape(len(tvtrain_images),1)"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "taZhNIigr-Oz",
        "outputId": "08e7493b-2367-4b3c-f991-1dfcec538102"
      },
      "source": [
        "tvtrain_labels.shape"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(850, 1)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0_15aitoF22z"
      },
      "source": [
        "##Neural Network Architecture\n",
        "A CNN base is used followed by some dense layers. The numpy arrays we created will come in handy here as it is easier to use an input. Using Keras, the model is constructed as given below. There are three convolutional layers with 16,32,32 filters each respectively along with two max pooling layers that pools with (5,5) size."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wCVlVWX97qi_"
      },
      "source": [
        "model = models.Sequential()\n",
        "model.add(layers.Conv2D(16, (8,8), activation='relu', input_shape=(800,400, 3)))\n",
        "model.add(layers.MaxPooling2D((5,5)))\n",
        "model.add(layers.Conv2D(32, (8,8), activation='relu'))\n",
        "model.add(layers.MaxPooling2D((5,5)))\n",
        "model.add(layers.Conv2D(32, (8,8), activation='relu'))"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DIAI4rbnG6f6"
      },
      "source": [
        "The dense part consists of a flattening layer which flattens the output of the final layer of CNN base. It is followed by another dense layer with 32 weights and then the output layer is created finally with a single unit that gives us the binary output of the image being a TV or not."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sZYxp9Uh-vJs"
      },
      "source": [
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(32, activation='relu'))\n",
        "model.add(layers.Dense(1))"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "twXimTIAHmdq"
      },
      "source": [
        "###Summary of the Model:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pJyBMRP1G-Ke",
        "outputId": "25644a5c-a58b-473d-d026-edd60148ffcd"
      },
      "source": [
        "model.summary()"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "conv2d (Conv2D)              (None, 793, 393, 16)      3088      \n",
            "_________________________________________________________________\n",
            "max_pooling2d (MaxPooling2D) (None, 158, 78, 16)       0         \n",
            "_________________________________________________________________\n",
            "conv2d_1 (Conv2D)            (None, 151, 71, 32)       32800     \n",
            "_________________________________________________________________\n",
            "max_pooling2d_1 (MaxPooling2 (None, 30, 14, 32)        0         \n",
            "_________________________________________________________________\n",
            "conv2d_2 (Conv2D)            (None, 23, 7, 32)         65568     \n",
            "_________________________________________________________________\n",
            "flatten (Flatten)            (None, 5152)              0         \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, 32)                164896    \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 1)                 33        \n",
            "=================================================================\n",
            "Total params: 266,385\n",
            "Trainable params: 266,385\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "CDjivR7ZISul"
      },
      "source": [
        "##Training and Testing\n",
        "The tensors tvtrain_images,tvtrain_labels is split into test and train data (0.15 split). Then the model created is trained with the usage of hyperparameters as stated in the code."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qvhXUHD5-4_z"
      },
      "source": [
        "from sklearn.model_selection import train_test_split"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0y9Wd9Vu_gr9"
      },
      "source": [
        "xtrain,xtest,ytrain,ytest=train_test_split(tvtrain_images,tvtrain_labels,test_size=0.15,random_state=0)"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oB4sVo1zANqV",
        "outputId": "b06ad215-422f-4701-a734-cf86b581b837"
      },
      "source": [
        "base_learning_rate = 0.0001\n",
        "model.compile(optimizer='adam',\n",
        "              loss=tf.keras.losses.BinaryCrossentropy(from_logits=True),\n",
        "              metrics=['accuracy'])\n",
        "\n",
        "history = model.fit(xtrain, ytrain, epochs=12, validation_data=(xtest,ytest))"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/12\n",
            "23/23 [==============================] - 5s 195ms/step - loss: 0.3626 - accuracy: 0.8518 - val_loss: 0.8157 - val_accuracy: 0.7812\n",
            "Epoch 2/12\n",
            "23/23 [==============================] - 4s 191ms/step - loss: 0.2150 - accuracy: 0.9030 - val_loss: 0.6225 - val_accuracy: 0.8047\n",
            "Epoch 3/12\n",
            "23/23 [==============================] - 4s 183ms/step - loss: 0.1109 - accuracy: 0.9598 - val_loss: 0.6653 - val_accuracy: 0.8203\n",
            "Epoch 4/12\n",
            "23/23 [==============================] - 4s 180ms/step - loss: 0.0684 - accuracy: 0.9737 - val_loss: 0.9225 - val_accuracy: 0.8281\n",
            "Epoch 5/12\n",
            "23/23 [==============================] - 4s 177ms/step - loss: 0.1121 - accuracy: 0.9640 - val_loss: 0.7115 - val_accuracy: 0.8359\n",
            "Epoch 6/12\n",
            "23/23 [==============================] - 4s 192ms/step - loss: 0.0899 - accuracy: 0.9709 - val_loss: 1.1453 - val_accuracy: 0.7812\n",
            "Epoch 7/12\n",
            "23/23 [==============================] - 4s 178ms/step - loss: 0.1745 - accuracy: 0.9363 - val_loss: 1.1010 - val_accuracy: 0.7266\n",
            "Epoch 8/12\n",
            "23/23 [==============================] - 4s 177ms/step - loss: 0.2158 - accuracy: 0.9183 - val_loss: 0.7765 - val_accuracy: 0.7891\n",
            "Epoch 9/12\n",
            "23/23 [==============================] - 4s 179ms/step - loss: 0.1208 - accuracy: 0.9626 - val_loss: 1.0264 - val_accuracy: 0.7969\n",
            "Epoch 10/12\n",
            "23/23 [==============================] - 4s 176ms/step - loss: 0.0712 - accuracy: 0.9765 - val_loss: 1.7571 - val_accuracy: 0.7109\n",
            "Epoch 11/12\n",
            "23/23 [==============================] - 4s 173ms/step - loss: 0.0450 - accuracy: 0.9820 - val_loss: 1.1972 - val_accuracy: 0.7891\n",
            "Epoch 12/12\n",
            "23/23 [==============================] - 4s 174ms/step - loss: 0.0213 - accuracy: 0.9903 - val_loss: 1.0799 - val_accuracy: 0.8281\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OSr_s46BJHwJ"
      },
      "source": [
        "Our Model has an accuracy of 82.81% which is good for an Image Processing model that only has 850 training images with few layers in the neural network."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Muib2S-_VSQ-"
      },
      "source": [
        "model.save(\"finding tv images.h5\") \n",
        "new_model = tf.keras.models.load_model('finding tv images.h5')"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "DamL0NNyJi8Y"
      },
      "source": [
        "Testing the model directly with any Image from the Internet:"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "olRmVs1CgSWk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a04809ce-2a5e-4605-b4b9-bba6aef3e8f9"
      },
      "source": [
        "tryimage=preprocess(\"\") #Input Image URL here\n",
        "tryimg=np.array(tryimage).reshape(1,800,400,3)\n",
        "model.predict(tryimg)\n",
        "# A positive value of higher magnitude usually means that it is a TV."
      ],
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-15.227043]], dtype=float32)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 29
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "YAltYEinJrSz"
      },
      "source": [
        "Use this link to open the [DuckDuckGo ImageScraper](https://colab.research.google.com/drive/16CaL8WJDat8Zjc0hJoK9-9cR41lB572U?usp=sharing)"
      ]
    }
  ]
}